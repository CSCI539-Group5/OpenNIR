{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexed EPIC\n",
    "\n",
    "[EPIC](https://arxiv.org/pdf/2004.14245.pdf) is a neural re-ranking model that builds efficient representations for re-ranking. In this example, we show how to build an epic index to speed up the re-ranking process.\n",
    "\n",
    "## Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/terrier-org/pyterrier\n",
    "!pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.4.0 has loaded Terrier 5.4 (built by craigm on 2021-01-16 14:17)\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init(tqdm='notebook')\n",
    "import onir_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy re-ranking\n",
    "\n",
    "We'll start by using a re-ranker that computes document representations as they are needed. Since this model uses BERT to build thiese representations, this process ends up taking a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 10:12:32,206][onir_pt][INFO] using cached checkpoint: /home/sean/data/onir/model_checkpoints/66273681b3ce24117dfda4b8ff58bad3\n"
     ]
    }
   ],
   "source": [
    "# Load a version of EPIC trained on the MS-MARCO dataset\n",
    "lazy_epic = onir_pt.reranker.from_checkpoint('https://macavaney.us/epic.msmarco.tar.gz', expected_md5=\"2f6a16be1a6a63aab1e8fed55521a4db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TREC COVID dataset for this example\n",
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cdeac34aed45c996fd8811accf5e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cord19/trec-covid documents:   0%|          | 0/192509 [15ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:32:29.824 [ForkJoinPool-1-worker-3] WARN  o.t.structures.indexing.Indexer - Adding an empty document to the index (6iu1dtyl) - further warnings are suppressed\n",
      "07:33:15.313 [ForkJoinPool-1-worker-3] WARN  o.t.structures.indexing.Indexer - Indexed 54937 empty documents\n"
     ]
    }
   ],
   "source": [
    "# Build an inverted index for TREC COIVID with pyterrier\n",
    "pt_index_path = './terrier_cord19'\n",
    "if not os.path.exists(pt_index_path + '/data.properties'):\n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path)\n",
    "    index_ref = indexer.index(dataset.get_corpus_iter(), fields=('abstract',), meta=('docno',))\n",
    "else:\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + '/data.properties')\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 07:33:22,932][onir_pt][DEBUG] using GPU (deterministic)\n",
      "[2021-03-12 07:33:22,939][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/375 [15ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 07:33:59,697][onir_pt][DEBUG] [finished] batches: [36.76s] [375it] [10.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_5</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RankCutoff(BR(DPH), 30)</td>\n",
       "      <td>0.766833</td>\n",
       "      <td>0.684</td>\n",
       "      <td>31.369397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(DPH), 30...</td>\n",
       "      <td>0.817889</td>\n",
       "      <td>0.724</td>\n",
       "      <td>768.649893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  recip_rank    P_5  \\\n",
       "0                            RankCutoff(BR(DPH), 30)    0.766833  0.684   \n",
       "1  Compose(Compose(Compose(RankCutoff(BR(DPH), 30...    0.817889  0.724   \n",
       "\n",
       "          mrt  \n",
       "0   31.369397  \n",
       "1  768.649893  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = pt.BatchRetrieve(index) % 30\n",
    "pipeline = br >> pt.text.get_text(dataset, 'abstract') >> pt.apply.generic(lambda x: x.rename(columns={'abstract': 'text'})) >> lazy_epic\n",
    "pt.Experiment(\n",
    "    [br, pipeline],\n",
    "    dataset.get_topics('title'),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[\"recip_rank\", \"P.5\", \"mrt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the mean response time (mrt) above, the lazy EPIC re-ranker is much slower than retrieving from the terrier index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-computing document vectors\n",
    "\n",
    "We can speed up the process by first computing all the document vectors. To do this, we use the `onir_pt.indexed_epic` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 07:34:33,488][onir_pt][INFO] using cached checkpoint: /home/sean/data/onir/model_checkpoints/66273681b3ce24117dfda4b8ff58bad3\n"
     ]
    }
   ],
   "source": [
    "indexed_epic = onir_pt.indexed_epic.from_checkpoint('https://macavaney.us/epic.msmarco.tar.gz',\n",
    "                                            index_path='./epic_cord19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814f7aec8d6d4ea5b41ba8390c590dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cord19/trec-covid documents:   0%|          | 0/192509 [19ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 07:34:44,500][onir_pt][DEBUG] using GPU (deterministic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "onir(epic,bert)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the documents. This takes some time, but it will end up saving a lot for mean response time.\n",
    "indexed_epic.index(dataset.get_corpus_iter(), fields=('abstract',), replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the index to speed up the re-ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 09:44:12,456][onir_pt][DEBUG] using GPU (deterministic)\n",
      "[2021-03-12 09:44:12,494][onir_pt][DEBUG] [starting] records\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "records:   0%|          | 0/1500 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-12 09:44:13,209][onir_pt][DEBUG] [finished] records: [713ms] [1500it] [2102.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_5</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RankCutoff(BR(DPH), 30)</td>\n",
       "      <td>0.766833</td>\n",
       "      <td>0.684</td>\n",
       "      <td>32.052374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(RankCutoff(BR(DPH), 30), onir(epic,bert))</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>0.700</td>\n",
       "      <td>47.084249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  recip_rank    P_5  \\\n",
       "0                            RankCutoff(BR(DPH), 30)    0.766833  0.684   \n",
       "1  Compose(RankCutoff(BR(DPH), 30), onir(epic,bert))    0.821500  0.700   \n",
       "\n",
       "         mrt  \n",
       "0  32.052374  \n",
       "1  47.084249  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = br >> indexed_epic.reranker()\n",
    "pt.Experiment(\n",
    "    [br, pipeline],\n",
    "    dataset.get_topics('title'),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[\"recip_rank\", \"P.5\", \"mrt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was much faster -- 721ms faster than the lazy version! And it's only 15ms slower than DPH (which it uses as a first-stage ranker).\n",
    "\n",
    "There is a slight change in effectiveness. This is because document vectors are pruned when indexed.\n",
    "\n",
    "Also notice how the indexed re-ranker does not need the document text anymore; that also saves some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
